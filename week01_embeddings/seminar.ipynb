{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "seminar.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrehPaItq6Xl",
        "colab_type": "text"
      },
      "source": [
        "## Seminar 1: Fun with Word Embeddings (3 points)\n",
        "\n",
        "Today we gonna play with word embeddings: train our own little embedding, load one from   gensim model zoo and use it to visualize text corpora.\n",
        "\n",
        "This whole thing is gonna happen on top of embedding dataset.\n",
        "\n",
        "__Requirements:__  `pip install --upgrade nltk gensim bokeh` , but only if you're running locally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J3XprwJq6Xz",
        "colab_type": "code",
        "outputId": "2a89af3c-6750-4091-a8c2-e6b76a809282",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "source": [
        "# download the data:\n",
        "!wget https://www.dropbox.com/s/obaitrix9jyu84r/quora.txt?dl=1 -O ./quora.txt\n",
        "# alternative download link: https://yadi.sk/i/BPQrUu1NaTduEw"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-01 12:50:09--  https://www.dropbox.com/s/obaitrix9jyu84r/quora.txt?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.1, 2620:100:601b:1::a27d:801\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/dl/obaitrix9jyu84r/quora.txt [following]\n",
            "--2019-12-01 12:50:09--  https://www.dropbox.com/s/dl/obaitrix9jyu84r/quora.txt\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc441fc11c407b183a1aa736b3a3.dl.dropboxusercontent.com/cd/0/get/Atb0XB9nAnkbypF75ae5ZhcWtCOnTuW6mhD4GuhyBCKAgUm9nFCDOoORNasflR34kiHC2gluLNbc2gEQTqiiyGs3Qc_y2_SfqgOWY-I7z3_-SQ/file?dl=1# [following]\n",
            "--2019-12-01 12:50:09--  https://uc441fc11c407b183a1aa736b3a3.dl.dropboxusercontent.com/cd/0/get/Atb0XB9nAnkbypF75ae5ZhcWtCOnTuW6mhD4GuhyBCKAgUm9nFCDOoORNasflR34kiHC2gluLNbc2gEQTqiiyGs3Qc_y2_SfqgOWY-I7z3_-SQ/file?dl=1\n",
            "Resolving uc441fc11c407b183a1aa736b3a3.dl.dropboxusercontent.com (uc441fc11c407b183a1aa736b3a3.dl.dropboxusercontent.com)... 162.125.8.6, 2620:100:6016:6::a27d:106\n",
            "Connecting to uc441fc11c407b183a1aa736b3a3.dl.dropboxusercontent.com (uc441fc11c407b183a1aa736b3a3.dl.dropboxusercontent.com)|162.125.8.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 33813903 (32M) [application/binary]\n",
            "Saving to: ‘./quora.txt’\n",
            "\n",
            "./quora.txt         100%[===================>]  32.25M  47.4MB/s    in 0.7s    \n",
            "\n",
            "2019-12-01 12:50:10 (47.4 MB/s) - ‘./quora.txt’ saved [33813903/33813903]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "UPFVpl-hq6YA",
        "colab_type": "code",
        "outputId": "75b58611-a361-4037-b86e-4e4951129260",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "data = list(open(\"./quora.txt\", encoding=\"utf-8\"))\n",
        "data[50]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"What TV shows or books help you read people's body language?\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0J3HZ6PPq6YO",
        "colab_type": "text"
      },
      "source": [
        "__Tokenization:__ a typical first step for an nlp task is to split raw data into words.\n",
        "The text we're working with is in raw format: with all the punctuation and smiles attached to some words, so a simple str.split won't do.\n",
        "\n",
        "Let's use __`nltk`__ - a library that handles many nlp tasks like tokenization, stemming or part-of-speech tagging."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPxwR_Teq6YR",
        "colab_type": "code",
        "outputId": "4953c6c9-994b-4d88-fccf-014a7b15ed42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from nltk.tokenize import WordPunctTokenizer\n",
        "tokenizer = WordPunctTokenizer()\n",
        "\n",
        "print(tokenizer.tokenize(data[50]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['What', 'TV', 'shows', 'or', 'books', 'help', 'you', 'read', 'people', \"'\", 's', 'body', 'language', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7T7G_P3q6Ya",
        "colab_type": "code",
        "outputId": "29a5e730-5c51-4188-d763-0f407325c513",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# TASK: lowercase everything and extract tokens with tokenizer. \n",
        "# data_tok should be a list of lists of tokens for each line in data.\n",
        "\n",
        "data_tok = []\n",
        "for line in data:\n",
        "  line_lower = []\n",
        "  for token in line:\n",
        "    line_lower.append(token.lower())\n",
        "  data_tok.append(tokenizer.tokenize(''.join(line_lower)))\n",
        "print(data_tok[50])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['what', 'tv', 'shows', 'or', 'books', 'help', 'you', 'read', 'people', \"'\", 's', 'body', 'language', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCR-XKFdq6Yj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert all(isinstance(row, (list, tuple)) for row in data_tok), \"please convert each line into a list of tokens (strings)\"\n",
        "assert all(all(isinstance(tok, str) for tok in row) for row in data_tok), \"please convert each line into a list of tokens (strings)\"\n",
        "is_latin = lambda tok: all('a' <= x.lower() <= 'z' for x in tok)\n",
        "assert all(map(lambda l: not is_latin(l) or l.islower(), map(' '.join, data_tok))), \"please make sure to lowercase the data\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txdeTQZHq6Yr",
        "colab_type": "code",
        "outputId": "e65751d5-670b-48cb-ec87-780a9968bc0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print([' '.join(row) for row in data_tok[:2]])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"can i get back with my ex even though she is pregnant with another guy ' s baby ?\", 'what are some ways to overcome a fast food addiction ?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmcEL2Nxq6Y2",
        "colab_type": "text"
      },
      "source": [
        "__Word vectors:__ as the saying goes, there's more than one way to train word embeddings. There's Word2Vec and GloVe with different objective functions. Then there's fasttext that uses character-level models to train word embeddings. \n",
        "\n",
        "The choice is huge, so let's start someplace small: __gensim__ is another nlp library that features many vector-based models incuding word2vec."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-U1AAB9Qq6Y5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "model = Word2Vec(data_tok, \n",
        "                 size=32,      # embedding vector size\n",
        "                 min_count=5,  # consider words that occured at least 5 times\n",
        "                 window=5).wv  # define context as a 5-word window around the target word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyT3m3zEq6ZD",
        "colab_type": "code",
        "outputId": "10fc2726-4746-430a-a7a7-87dde3e12cc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "# now you can get word vectors !\n",
        "model.get_vector('anything')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-2.2009997 , -0.1387195 , -0.6024568 , -1.6172652 ,  1.1222405 ,\n",
              "       -0.0379198 , -2.678455  ,  0.61803514,  0.1896913 , -2.5656643 ,\n",
              "       -0.4124966 ,  4.8903813 , -0.8199142 , -2.5211842 ,  0.28437877,\n",
              "       -2.3627021 ,  5.7170095 ,  0.10826262, -1.3994116 , -3.1991165 ,\n",
              "       -0.5908269 , -1.3386352 , -0.6752963 , -2.2488084 ,  1.1701473 ,\n",
              "       -1.9430925 , -0.04954077,  1.4207548 ,  1.6645294 ,  2.233626  ,\n",
              "       -0.75584686,  0.91023725], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LND8-DaDq6ZL",
        "colab_type": "code",
        "outputId": "7f6f3f3e-3498-4411-8073-7c0e758456a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# or query similar words directly. Go play with it!\n",
        "model.most_similar('bread')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('rice', 0.9440542459487915),\n",
              " ('sauce', 0.9328721761703491),\n",
              " ('chocolate', 0.9301918148994446),\n",
              " ('cheese', 0.9260110855102539),\n",
              " ('pasta', 0.9241026639938354),\n",
              " ('soup', 0.9230953454971313),\n",
              " ('potatoes', 0.9218540191650391),\n",
              " ('potato', 0.9191493391990662),\n",
              " ('butter', 0.917066216468811),\n",
              " ('garlic', 0.916756808757782)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxjlxDq-q6ZU",
        "colab_type": "text"
      },
      "source": [
        "### Using pre-trained model\n",
        "\n",
        "Took it a while, huh? Now imagine training life-sized (100~300D) word embeddings on gigabytes of text: wikipedia articles or twitter posts. \n",
        "\n",
        "Thankfully, nowadays you can get a pre-trained word embedding model in 2 lines of code (no sms required, promise)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cl7xGFOAq6ZX",
        "colab_type": "code",
        "outputId": "c9d2403d-a5cc-4838-8f0f-a1f3339cce95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "import gensim.downloader as api\n",
        "model = api.load('glove-twitter-100')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[=================================================-] 98.7% 382.2/387.1MB downloaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zY9RSnXBq6Zg",
        "colab_type": "code",
        "outputId": "35a92551-c5e8-42a1-f7ab-e14aef1099fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "model.most_similar(positive=[\"coder\", \"money\"], negative=[\"brain\"])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('broker', 0.5820155739784241),\n",
              " ('bonuses', 0.5424473285675049),\n",
              " ('banker', 0.538511335849762),\n",
              " ('designer', 0.5197198390960693),\n",
              " ('merchandising', 0.4964233934879303),\n",
              " ('treet', 0.49220192432403564),\n",
              " ('shopper', 0.4920561909675598),\n",
              " ('part-time', 0.49128279089927673),\n",
              " ('freelance', 0.4843311905860901),\n",
              " ('aupair', 0.4796452522277832)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUfPj_Ubq6Zp",
        "colab_type": "text"
      },
      "source": [
        "### Visualizing word vectors\n",
        "\n",
        "One way to see if our vectors are any good is to plot them. Thing is, those vectors are in 30D+ space and we humans are more used to 2-3D.\n",
        "\n",
        "Luckily, we machine learners know about __dimensionality reduction__ methods.\n",
        "\n",
        "Let's use that to plot 1000 most frequent words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kfd71eG9bgd5",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ookj1f_Qq6Zs",
        "colab_type": "code",
        "outputId": "e236797a-d6ef-4e61-b303-4c96735a4989",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "words = sorted(model.vocab.keys(), \n",
        "               key=lambda word: model.vocab[word].count,\n",
        "               reverse=True)[:1000]\n",
        "\n",
        "print(words[::100])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<user>', '_', 'please', 'apa', 'justin', 'text', 'hari', 'playing', 'once', 'sei']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9KHZtn5Gzk5",
        "colab_type": "code",
        "outputId": "a3d2b843-848c-4347-c183-cd91b5b7df9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(words[:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<user>', '.', ':', 'rt', ',', '<repeat>', '<hashtag>', '<number>', '<url>', '!']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2_oJuDyq6Z1",
        "colab_type": "code",
        "outputId": "bbdb290a-d132-4baf-d205-bdde69895e08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        }
      },
      "source": [
        "# for each word, compute its vector with model\n",
        "word_vectors = []\n",
        "for word in words:\n",
        "  word_vectors.append(model.get_vector(word))\n",
        "word_vectors = np.asarray(word_vectors)\n",
        "print(word_vectors[:2])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.63006    0.65177    0.25545    0.018593   0.043094   0.047194\n",
            "   0.23218    0.11613    0.17371    0.40487    0.022524  -0.076731\n",
            "  -2.2911     0.094127   0.43293    0.041801   0.063175  -0.64486\n",
            "  -0.43657    0.024114  -0.082989   0.21686   -0.13462   -0.22336\n",
            "   0.39436   -2.1724    -0.39544    0.16536    0.39438   -0.35182\n",
            "  -0.14996    0.10502   -0.45937    0.27729    0.8924    -0.042313\n",
            "  -0.009345   0.55017    0.095521   0.070504  -1.1781     0.013723\n",
            "   0.17742    0.74142    0.17716    0.038468  -0.31684    0.08941\n",
            "   0.20557   -0.34328   -0.64303   -0.878     -0.16293   -0.055925\n",
            "   0.33898    0.60664   -0.2774     0.33626    0.21603   -0.11051\n",
            "   0.0058673 -0.64757   -0.068222  -0.77414    0.13911   -0.15851\n",
            "  -0.61885   -0.10192   -0.47       0.19787    0.42175   -0.18458\n",
            "   0.080581  -0.22545   -0.065129  -0.15328    0.087726  -0.18817\n",
            "  -0.08371    0.21779    0.97899    0.1092     0.022705  -0.078234\n",
            "   0.15595    0.083105  -0.6824     0.57469   -0.19942    0.50566\n",
            "  -0.18277    0.37721   -0.12514   -0.42821   -0.81075   -0.39326\n",
            "  -0.17386    0.55096    0.64706   -0.6093   ]\n",
            " [ 0.18205   -0.048483   0.23966    0.32099   -0.27002    0.70431\n",
            "  -0.21257    0.235      0.090142   0.82141    0.37843   -0.56382\n",
            "  -2.4447     0.16827    0.24685    0.28649    0.062312   0.067508\n",
            "  -0.58459   -0.45414   -0.22158    0.17423   -0.35558    0.14485\n",
            "   0.49089   -1.7426    -0.54306   -0.51937    0.94795   -0.41739\n",
            "  -0.55238   -0.057398  -0.52663    0.62976    0.097275   0.20637\n",
            "   0.46261    0.089462   0.016019  -0.53854   -1.2043     0.080287\n",
            "  -0.65351    0.044617   0.79527    0.044508   0.53367    0.27444\n",
            "  -0.32461   -0.053683  -0.79304    0.11       0.39762   -0.044155\n",
            "   0.21701    0.27977   -0.25773    0.25085    0.39711    0.32318\n",
            "   0.10245   -0.030471   0.34113    0.17971    0.44436    0.054915\n",
            "   0.22461   -0.80843   -0.11052    0.42366    0.61091    0.55024\n",
            "   0.21958   -0.3029     0.14545   -0.46701   -0.23945    0.035106\n",
            "  -0.50933   -0.12392    0.24526    0.14758   -0.30313   -0.53052\n",
            "   0.80632    0.34566   -0.24541    0.71479   -0.15985    0.40129\n",
            "  -0.10851   -0.61427   -0.0035577  0.037739  -0.33055   -0.094383\n",
            "   0.38617   -0.3358     0.18884   -0.40786  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ue06BZEyq6Z8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert isinstance(word_vectors, np.ndarray)\n",
        "assert word_vectors.shape == (len(words), 100)\n",
        "assert np.isfinite(word_vectors).all()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBUqDPlaq6aH",
        "colab_type": "text"
      },
      "source": [
        "#### Linear projection: PCA\n",
        "\n",
        "The simplest linear dimensionality reduction method is __P__rincipial __C__omponent __A__nalysis.\n",
        "\n",
        "In geometric terms, PCA tries to find axes along which most of the variance occurs. The \"natural\" axes, if you wish.\n",
        "\n",
        "<img src=\"https://github.com/yandexdataschool/Practical_RL/raw/master/yet_another_week/_resource/pca_fish.png\" style=\"width:30%\">\n",
        "\n",
        "\n",
        "Under the hood, it attempts to decompose object-feature matrix $X$ into two smaller matrices: $W$ and $\\hat W$ minimizing _mean squared error_:\n",
        "\n",
        "$$\\|(X W) \\hat{W} - X\\|^2_2 \\to_{W, \\hat{W}} \\min$$\n",
        "- $X \\in \\mathbb{R}^{n \\times m}$ - object matrix (**centered**);\n",
        "- $W \\in \\mathbb{R}^{m \\times d}$ - matrix of direct transformation;\n",
        "- $\\hat{W} \\in \\mathbb{R}^{d \\times m}$ - matrix of reverse transformation;\n",
        "- $n$ samples, $m$ original dimensions and $d$ target dimensions;\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTGBLThDq6aK",
        "colab_type": "code",
        "outputId": "63fba61f-85bb-4737-dd54-7009102b2df2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "# map word vectors onto 2d plane with PCA. Use good old sklearn api (fit, transform)\n",
        "# after that, normalize vectors to make sure they have zero mean and unit variance\n",
        "pca = PCA(n_components=2)\n",
        "word_vectors_pca = pca.fit_transform(word_vectors)\n",
        "print(word_vectors_pca)\n",
        "word_vectors_pca = StandardScaler().fit_transform(word_vectors_pca)\n",
        "print(word_vectors_pca)\n",
        "#word_vectors_pca = pd.DataFrame(data = principal_components, columns = ['principal component 1', 'principal component 2'])\n",
        "#word_vectors_pca = # YOUR CODE\n",
        "\n",
        "# and maybe MORE OF YOUR CODE here :)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.93338627  0.5037088 ]\n",
            " [ 0.7293041   0.36442262]\n",
            " [ 1.1819209   0.6137338 ]\n",
            " ...\n",
            " [ 2.5400124  -2.304001  ]\n",
            " [-0.07835463  0.486361  ]\n",
            " [-2.0053232  -0.2208064 ]]\n",
            "[[ 0.388168    0.29139465]\n",
            " [ 0.30329645  0.21081796]\n",
            " [ 0.49152595  0.3550439 ]\n",
            " ...\n",
            " [ 1.0563148  -1.3328586 ]\n",
            " [-0.03258419  0.28135902]\n",
            " [-0.83395165 -0.12773558]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkplwz0oXs8U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8eENmtYq6aT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert word_vectors_pca.shape == (len(word_vectors), 2), \"there must be a 2d vector for each word\"\n",
        "assert max(abs(word_vectors_pca.mean(0))) < 1e-5, \"points must be zero-centered\"\n",
        "assert max(abs(1.0 - word_vectors_pca.std(0))) < 1e-2, \"points must have unit variance\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWCEc4oUq6ab",
        "colab_type": "text"
      },
      "source": [
        "#### Let's draw it!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6fCShfjq6ad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import bokeh.models as bm, bokeh.plotting as pl\n",
        "from bokeh.io import output_notebook\n",
        "output_notebook()\n",
        "\n",
        "def draw_vectors(x, y, radius=10, alpha=0.25, color='blue',\n",
        "                 width=600, height=400, show=True, **kwargs):\n",
        "    \"\"\" draws an interactive plot for data points with auxilirary info on hover \"\"\"\n",
        "    if isinstance(color, str): color = [color] * len(x)\n",
        "    data_source = bm.ColumnDataSource({ 'x' : x, 'y' : y, 'color': color, **kwargs })\n",
        "\n",
        "    fig = pl.figure(active_scroll='wheel_zoom', width=width, height=height)\n",
        "    fig.scatter('x', 'y', size=radius, color='color', alpha=alpha, source=data_source)\n",
        "\n",
        "    fig.add_tools(bm.HoverTool(tooltips=[(key, \"@\" + key) for key in kwargs.keys()]))\n",
        "    if show: pl.show(fig)\n",
        "    return fig"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KtztLg1q6an",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "outputId": "56ea980c-7724-4654-c608-ab855934400b"
      },
      "source": [
        "draw_vectors(word_vectors_pca[:, 0], word_vectors_pca[:, 1], token=words)\n",
        "\n",
        "# hover a mouse over there and see if you can identify the clusters"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "(function(root) {\n",
              "  function now() {\n",
              "    return new Date();\n",
              "  }\n",
              "\n",
              "  var force = true;\n",
              "\n",
              "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
              "    root._bokeh_onload_callbacks = [];\n",
              "    root._bokeh_is_loading = undefined;\n",
              "  }\n",
              "\n",
              "  var JS_MIME_TYPE = 'application/javascript';\n",
              "  var HTML_MIME_TYPE = 'text/html';\n",
              "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
              "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
              "\n",
              "  /**\n",
              "   * Render data to the DOM node\n",
              "   */\n",
              "  function render(props, node) {\n",
              "    var script = document.createElement(\"script\");\n",
              "    node.appendChild(script);\n",
              "  }\n",
              "\n",
              "  /**\n",
              "   * Handle when an output is cleared or removed\n",
              "   */\n",
              "  function handleClearOutput(event, handle) {\n",
              "    var cell = handle.cell;\n",
              "\n",
              "    var id = cell.output_area._bokeh_element_id;\n",
              "    var server_id = cell.output_area._bokeh_server_id;\n",
              "    // Clean up Bokeh references\n",
              "    if (id != null && id in Bokeh.index) {\n",
              "      Bokeh.index[id].model.document.clear();\n",
              "      delete Bokeh.index[id];\n",
              "    }\n",
              "\n",
              "    if (server_id !== undefined) {\n",
              "      // Clean up Bokeh references\n",
              "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
              "      cell.notebook.kernel.execute(cmd, {\n",
              "        iopub: {\n",
              "          output: function(msg) {\n",
              "            var id = msg.content.text.trim();\n",
              "            if (id in Bokeh.index) {\n",
              "              Bokeh.index[id].model.document.clear();\n",
              "              delete Bokeh.index[id];\n",
              "            }\n",
              "          }\n",
              "        }\n",
              "      });\n",
              "      // Destroy server and session\n",
              "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
              "      cell.notebook.kernel.execute(cmd);\n",
              "    }\n",
              "  }\n",
              "\n",
              "  /**\n",
              "   * Handle when a new output is added\n",
              "   */\n",
              "  function handleAddOutput(event, handle) {\n",
              "    var output_area = handle.output_area;\n",
              "    var output = handle.output;\n",
              "\n",
              "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
              "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
              "      return\n",
              "    }\n",
              "\n",
              "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
              "\n",
              "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
              "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
              "      // store reference to embed id on output_area\n",
              "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
              "    }\n",
              "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
              "      var bk_div = document.createElement(\"div\");\n",
              "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
              "      var script_attrs = bk_div.children[0].attributes;\n",
              "      for (var i = 0; i < script_attrs.length; i++) {\n",
              "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
              "      }\n",
              "      // store reference to server id on output_area\n",
              "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
              "    }\n",
              "  }\n",
              "\n",
              "  function register_renderer(events, OutputArea) {\n",
              "\n",
              "    function append_mime(data, metadata, element) {\n",
              "      // create a DOM node to render to\n",
              "      var toinsert = this.create_output_subarea(\n",
              "        metadata,\n",
              "        CLASS_NAME,\n",
              "        EXEC_MIME_TYPE\n",
              "      );\n",
              "      this.keyboard_manager.register_events(toinsert);\n",
              "      // Render to node\n",
              "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
              "      render(props, toinsert[toinsert.length - 1]);\n",
              "      element.append(toinsert);\n",
              "      return toinsert\n",
              "    }\n",
              "\n",
              "    /* Handle when an output is cleared or removed */\n",
              "    events.on('clear_output.CodeCell', handleClearOutput);\n",
              "    events.on('delete.Cell', handleClearOutput);\n",
              "\n",
              "    /* Handle when a new output is added */\n",
              "    events.on('output_added.OutputArea', handleAddOutput);\n",
              "\n",
              "    /**\n",
              "     * Register the mime type and append_mime function with output_area\n",
              "     */\n",
              "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
              "      /* Is output safe? */\n",
              "      safe: true,\n",
              "      /* Index of renderer in `output_area.display_order` */\n",
              "      index: 0\n",
              "    });\n",
              "  }\n",
              "\n",
              "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
              "  if (root.Jupyter !== undefined) {\n",
              "    var events = require('base/js/events');\n",
              "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
              "\n",
              "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
              "      register_renderer(events, OutputArea);\n",
              "    }\n",
              "  }\n",
              "\n",
              "  \n",
              "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
              "    root._bokeh_timeout = Date.now() + 5000;\n",
              "    root._bokeh_failed_load = false;\n",
              "  }\n",
              "\n",
              "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
              "     \"<div style='background-color: #fdd'>\\n\"+\n",
              "     \"<p>\\n\"+\n",
              "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
              "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
              "     \"</p>\\n\"+\n",
              "     \"<ul>\\n\"+\n",
              "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
              "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
              "     \"</ul>\\n\"+\n",
              "     \"<code>\\n\"+\n",
              "     \"from bokeh.resources import INLINE\\n\"+\n",
              "     \"output_notebook(resources=INLINE)\\n\"+\n",
              "     \"</code>\\n\"+\n",
              "     \"</div>\"}};\n",
              "\n",
              "  function display_loaded() {\n",
              "    var el = document.getElementById(null);\n",
              "    if (el != null) {\n",
              "      el.textContent = \"BokehJS is loading...\";\n",
              "    }\n",
              "    if (root.Bokeh !== undefined) {\n",
              "      if (el != null) {\n",
              "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
              "      }\n",
              "    } else if (Date.now() < root._bokeh_timeout) {\n",
              "      setTimeout(display_loaded, 100)\n",
              "    }\n",
              "  }\n",
              "\n",
              "\n",
              "  function run_callbacks() {\n",
              "    try {\n",
              "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
              "    }\n",
              "    finally {\n",
              "      delete root._bokeh_onload_callbacks\n",
              "    }\n",
              "    console.info(\"Bokeh: all callbacks have finished\");\n",
              "  }\n",
              "\n",
              "  function load_libs(js_urls, callback) {\n",
              "    root._bokeh_onload_callbacks.push(callback);\n",
              "    if (root._bokeh_is_loading > 0) {\n",
              "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
              "      return null;\n",
              "    }\n",
              "    if (js_urls == null || js_urls.length === 0) {\n",
              "      run_callbacks();\n",
              "      return null;\n",
              "    }\n",
              "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
              "    root._bokeh_is_loading = js_urls.length;\n",
              "    for (var i = 0; i < js_urls.length; i++) {\n",
              "      var url = js_urls[i];\n",
              "      var s = document.createElement('script');\n",
              "      s.src = url;\n",
              "      s.async = false;\n",
              "      s.onreadystatechange = s.onload = function() {\n",
              "        root._bokeh_is_loading--;\n",
              "        if (root._bokeh_is_loading === 0) {\n",
              "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
              "          run_callbacks()\n",
              "        }\n",
              "      };\n",
              "      s.onerror = function() {\n",
              "        console.warn(\"failed to load library \" + url);\n",
              "      };\n",
              "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
              "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "    }\n",
              "  };\n",
              "\n",
              "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.4.min.js\"];\n",
              "\n",
              "  var inline_js = [\n",
              "    function(Bokeh) {\n",
              "      Bokeh.set_log_level(\"info\");\n",
              "    },\n",
              "    \n",
              "    function(Bokeh) {\n",
              "      \n",
              "    },\n",
              "    function(Bokeh) {\n",
              "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.css\");\n",
              "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.css\");\n",
              "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.css\");\n",
              "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.css\");\n",
              "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.css\");\n",
              "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.css\");\n",
              "    }\n",
              "  ];\n",
              "\n",
              "  function run_inline_js() {\n",
              "    \n",
              "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
              "      for (var i = 0; i < inline_js.length; i++) {\n",
              "        inline_js[i].call(root, root.Bokeh);\n",
              "      }} else if (Date.now() < root._bokeh_timeout) {\n",
              "      setTimeout(run_inline_js, 100);\n",
              "    } else if (!root._bokeh_failed_load) {\n",
              "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
              "      root._bokeh_failed_load = true;\n",
              "    } else if (force !== true) {\n",
              "      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n",
              "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
              "    }\n",
              "\n",
              "  }\n",
              "\n",
              "  if (root._bokeh_is_loading === 0) {\n",
              "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
              "    run_inline_js();\n",
              "  } else {\n",
              "    load_libs(js_urls, function() {\n",
              "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
              "      run_inline_js();\n",
              "    });\n",
              "  }\n",
              "}(window));"
            ],
            "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(null);\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.4.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "  <div class=\"bk-root\" id=\"91b43ce5-c674-40fb-abe3-253302069d3d\" data-root-id=\"1002\"></div>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "(function(root) {\n",
              "  function embed_document(root) {\n",
              "    \n",
              "  var docs_json = {\"df5b4d75-669a-431a-b23b-4a87510aa0c8\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1011\",\"type\":\"LinearAxis\"}],\"left\":[{\"id\":\"1016\",\"type\":\"LinearAxis\"}],\"plot_height\":400,\"renderers\":[{\"id\":\"1011\",\"type\":\"LinearAxis\"},{\"id\":\"1015\",\"type\":\"Grid\"},{\"id\":\"1016\",\"type\":\"LinearAxis\"},{\"id\":\"1020\",\"type\":\"Grid\"},{\"id\":\"1029\",\"type\":\"BoxAnnotation\"},{\"id\":\"1039\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"1044\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"1027\",\"type\":\"Toolbar\"},\"x_range\":{\"id\":\"1003\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"1007\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"1005\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"1009\",\"type\":\"LinearScale\"}},\"id\":\"1002\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"plot\":{\"id\":\"1002\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"1012\",\"type\":\"BasicTicker\"}},\"id\":\"1015\",\"type\":\"Grid\"},{\"attributes\":{\"formatter\":{\"id\":\"1048\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"1002\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"1017\",\"type\":\"BasicTicker\"}},\"id\":\"1016\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1024\",\"type\":\"SaveTool\"},{\"attributes\":{\"overlay\":{\"id\":\"1029\",\"type\":\"BoxAnnotation\"}},\"id\":\"1023\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"formatter\":{\"id\":\"1046\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"1002\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"1012\",\"type\":\"BasicTicker\"}},\"id\":\"1011\",\"type\":\"LinearAxis\"},{\"attributes\":{\"source\":{\"id\":\"1001\",\"type\":\"ColumnDataSource\"}},\"id\":\"1040\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1021\",\"type\":\"PanTool\"},{\"attributes\":{\"callback\":null,\"data\":{\"color\":[\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\"],\"token\":[\"<user>\",\".\",\":\",\"rt\",\",\",\"<repeat>\",\"<hashtag>\",\"<number>\",\"<url>\",\"!\",\"i\",\"a\",\"\\\"\",\"the\",\"?\",\"you\",\"to\",\"(\",\"<allcaps>\",\"<elong>\",\")\",\"me\",\"de\",\"<smile>\",\"\\uff01\",\"que\",\"and\",\"\\u3002\",\"-\",\"my\",\"no\",\"\\u3001\",\"is\",\"it\",\"\\u2026\",\"in\",\"n\",\"for\",\"/\",\"of\",\"la\",\"'s\",\"*\",\"do\",\"n't\",\"that\",\"on\",\"y\",\"'\",\"e\",\"o\",\"u\",\"en\",\"this\",\"el\",\"so\",\"be\",\"'m\",\"with\",\"just\",\">\",\"your\",\"^\",\"like\",\"have\",\"te\",\"at\",\"\\uff1f\",\"love\",\"se\",\"are\",\"<\",\"m\",\"r\",\"if\",\"all\",\"b\",\"\\u30fb\",\"not\",\"but\",\"we\",\"es\",\"ya\",\"&\",\"follow\",\"up\",\"what\",\"get\",\"lol\",\"un\",\"\\u2665\",\"lo\",\"when\",\"was\",\"\\u201c\",\"\\u201d\",\"one\",\"por\",\"si\",\"out\",\"_\",\"mi\",\"can\",\"<sadface>\",\"\\u0645\\u0646\",\"\\u2661\",\"\\u00b4\",\"he\",\"con\",\"they\",\"now\",\"go\",\"\\u060c\",\"para\",\"los\",\"know\",\"haha\",\"good\",\"tu\",\"back\",\"~\",\"about\",\"new\",\";\",\"as\",\"day\",\"how\",\"who\",\"will\",\"want\",\"people\",\"yo\",\"eu\",\"from\",\"di\",\"time\",\"<heart>\",\"s\",\"aku\",\"da\",\"'re\",\"<lolface>\",\"una\",\"got\",\"las\",\"more\",\"x\",\"she\",\"today\",\"\\uff08\",\">>\",\"k\",\"by\",\"or\",\"\\u0641\\u064a\",\"\\uff65\",\"too\",\"le\",\"\\u00e9\",\"|\",\"[\",\"\\uff09\",\"]\",\"see\",\"why\",\"yg\",\"ca\",\"como\",\"her\",\"\\u2014\",\"q\",\"need\",\"an\",\"na\",\"\\u7b11\",\"there\",\"\\u03c9\",\"happy\",\"im\",\"mas\",\"je\",\"life\",\"really\",\"make\",\"yang\",\"shit\",\"think\",\"t\",\"\\u2764\",\"n\\u00e3o\",\"never\",\"some\",\"\\uff5e\",\"oh\",\"\\u2605\",\"did\",\"would\",\"del\",\"`\",\"d\",\"please\",\"via\",\"much\",\"fuck\",\"al\",\"dia\",\"$\",\"\\u0648\",\"right\",\"best\",\"c\",\"going\",\"\\u0627\\u0644\\u0644\\u0647\",\"pero\",\"only\",\"has\",\"\\u266a\",\"'ll\",\"twitter\",\"=\",\"hahaha\",\"its\",\"nn\",\"\\uff40\",\"\\u00bf\",\"am\",\"say\",\"<neutralface>\",\"them\",\"here\",\"\\u0644\\u0627\",\"off\",\"still\",\"dan\",\"+\",\"night\",\"w\",\"ada\",\"someone\",\"even\",\"then\",\"\\u2606\",\"ni\",\"come\",\"com\",\"always\",\"man\",\"'ve\",\"been\",\"his\",\"itu\",\"\\u0639\\u0644\\u0649\",\"-_-\",\"\\u263a\",\"over\",\"um\",\"\\u0645\\u0627\",\"hate\",\"girl\",\"ai\",\"had\",\"pra\",\"todo\",\"mais\",\"feel\",\"let\",\"ini\",\"because\",\"\\uff9f\",\"thanks\",\"ah\",\"way\",\"ever\",\"look\",\"tweet\",\"followers\",\"should\",\"our\",\"xd\",\"aja\",\"esta\",\"school\",\"him\",\"ser\",\"take\",\"than\",\"video\",\"em\",\"last\",\"wanna\",\"does\",\"us\",\"miss\",\"l\",\"ga\",\"better\",\"well\",\"could\",\"\\u25bd\",\"%\",\"apa\",\"cuando\",\"team\",\"\\u2714\",\"@\",\"ok\",\"\\u061f\",\"\\u2022\",\"vida\",\"quiero\",\"les\",\"being\",\"real\",\"down\",\"kamu\",\"everyone\",\"gonna\",\"live\",\"tonight\",\"yes\",\"work\",\"ass\",\"retweet\",\"nada\",\"sama\",\"first\",\"<<\",\"photo\",\"tomorrow\",\"where\",\"god\",\"son\",\"ke\",\"ta\",\"f\",\"home\",\"lagi\",\"thank\",\"birthday\",\"\\u2588\",\"ha\",\"great\",\"lmao\",\"omg\",\"morning\",\"m\\u00e1s\",\"mau\",\"baby\",\"dont\",\"\\uff61\",\"their\",\"p\",\"things\",\"game\",\"pas\",\"bad\",\"year\",\"yeah\",\"su\",\"bitch\",\"\\u0432\",\"stop\",\"hoy\",\"something\",\"meu\",\"tak\",\"gak\",\"world\",\"amor\",\"h\",\"\\\\\",\"ver\",\"\\uff1b\",\"porque\",\"give\",\"these\",\"\\u0627\\u0644\\u0644\\u0647\\u0645\",\"were\",\"hay\",\"sleep\",\"gue\",\"every\",\"friends\",\"uma\",\"tell\",\"amo\",\"vou\",\"bien\",\"\\u00a1\",\"again\",\"\\uff3e\",\"\\uff0f\",\"done\",\"after\",\"todos\",\"girls\",\"guys\",\"getting\",\"big\",\"wait\",\"justin\",\"eh\",\"\\u2192\",\"kan\",\"kita\",\"jajaja\",\"wish\",\"said\",\"fucking\",\"show\",\"thing\",\"next\",\"voc\\u00ea\",\"nos\",\"little\",\"tengo\",\"keep\",\"person\",\"''\",\"\\u2200\",\"hope\",\"\\u0643\\u0644\",\"hey\",\"bisa\",\"free\",\"made\",\"foto\",\"va\",\"everything\",\"iya\",\"nigga\",\"eso\",\"et\",\"watch\",\"music\",\"week\",\"talk\",\"ne\",\"solo\",\"gente\",\"udah\",\"\\uff1a\",\"--\",\"\\uff3c\",\"mejor\",\"facebook\",\"ma\",\"v\",\"phone\",\"most\",\"same\",\"okay\",\"ik\",\"before\",\"minha\",\"days\",\"g\",\"ti\",\"damn\",\"nice\",\"voy\",\"vai\",\"call\",\"long\",\"tapi\",\"http\",\"sin\",\"nunca\",\"doing\",\"other\",\"find\",\"il\",\"sa\",\"sorry\",\"nya\",\"orang\",\"\\u00b0\",\"hard\",\"mean\",\"die\",\"\\u0627\\u0644\\u0644\\u064a\",\"tem\",\"soy\",\"este\",\"kalo\",\"s\\u00f3\",\"th\",\"win\",\"nothing\",\"into\",\"face\",\"cute\",\"'d\",\"gracias\",\"lah\",\"\\u0438\",\"any\",\"play\",\"\\u2190\",\"ko\",\"text\",\"\\u2323\",\"estoy\",\"tau\",\"ur\",\"buat\",\"#\",\"cause\",\"\\u044f\",\"put\",\"kau\",\"siempre\",\"juga\",\"casa\",\"\\u0623\\u0646\",\"help\",\"start\",\"feliz\",\"old\",\"ir\",\"very\",\"care\",\"bir\",\"makes\",\"song\",\"check\",\"watching\",\"ahora\",\"jadi\",\"os\",\"may\",\"friend\",\"beautiful\",\"heart\",\"ka\",\"vc\",\"mundo\",\"\\u043d\\u0430\",\"sure\",\"tan\",\"pretty\",\"aqui\",\"\\u043d\\u0435\",\"house\",\"\\u0631\\u062a\\u0648\\u064a\\u062a\",\"\\u064a\\u0627\",\"ja\",\"true\",\"muy\",\"away\",\"already\",\"actually\",\"believe\",\"try\",\"many\",\"ma\\u00f1ana\",\"mis\",\"lu\",\"those\",\"hot\",\"qu\\u00e9\",\"mal\",\"\\u0639\\u0646\",\"though\",\"ask\",\"amazing\",\"bed\",\"}\",\"two\",\"mom\",\"d\\u00eda\",\"ve\",\"dari\",\"gameinsight\",\"stay\",\"fun\",\"around\",\"van\",\"cont\",\"ready\",\"money\",\"bu\",\"funny\",\"cool\",\"hair\",\"\\u00e0\",\"tho\",\"{\",\"wo\",\"hi\",\"name\",\"tiene\",\"hahahaha\",\"pa\",\"algo\",\"gotta\",\"\\u0648\\u0644\\u0627\",\"boy\",\"another\",\"c'est\",\"hari\",\"jajajaja\",\"having\",\"cara\",\"jaja\",\"dm\",\"looking\",\"top\",\"android\",\"dah\",\"wow\",\"\\u2591\",\"eres\",\"ben\",\"must\",\"news\",\"met\",\"est\\u00e1\",\"nih\",\"family\",\"black\",\"thought\",\"nak\",\"super\",\"end\",\"hace\",\"remember\",\"ama\",\"party\",\"cant\",\"vamos\",\"anything\",\"anyone\",\"\\u0641\\u0648\\u0644\\u0648\",\"perfect\",\"guy\",\"vez\",\"christmas\",\"dos\",\"bueno\",\"nao\",\"years\",\"vote\",\"dormir\",\"bro\",\"else\",\"quien\",\"untuk\",\"jangan\",\"myself\",\"head\",\"mind\",\"gua\",\"talking\",\"while\",\"dat\",\"food\",\"\\u0434\",\"coming\",\"wkwk\",\"trying\",\"saya\",\"mucho\",\"without\",\"wrong\",\"\\u2019s\",\"baru\",\"__\",\"hehe\",\"hacer\",\"lot\",\"followed\",\"crazy\",\"hell\",\"feeling\",\"des\",\"kok\",\"j\",\"stats\",\"j'\",\"\\u0627\\u0646\",\"tweets\",\"non\",\"cosas\",\"era\",\"high\",\"niggas\",\"change\",\"movie\",\"xx\",\"mad\",\"sih\",\"sometimes\",\"deh\",\"allah\",\"through\",\"pour\",\"ela\",\"soon\",\"gone\",\"playing\",\"smile\",\"bukan\",\"tv\",\"fans\",\"hasta\",\"akan\",\"y'\",\"looks\",\"isso\",\"\\u270c\",\"tired\",\"boys\",\"might\",\"dong\",\"lg\",\"use\",\"maybe\",\"until\",\"menos\",\"own\",\"dengan\",\"eat\",\"ou\",\"weekend\",\"\\u02d8\",\"class\",\"ele\",\"harry\",\"iphone\",\"friday\",\"single\",\"ff\",\"awesome\",\"bout\",\"muito\",\"hoje\",\"\\u00ac\",\"dios\",\"such\",\"estar\",\"j\\u00e1\",\"quando\",\"esa\",\"making\",\"\\u2501\",\"times\",\"lmfao\",\"gw\",\"moment\",\"yet\",\"aw\",\"smh\",\"banget\",\"masih\",\"qui\",\"quem\",\"\\u2013\",\"leave\",\"du\",\"une\",\"guess\",\"hit\",\"\\u0441\",\"pm\",\"since\",\"pues\",\"est\",\"job\",\"\\uff89\",\"mana\",\"bom\",\"siapa\",\"suka\",\"bieber\",\"mention\",\"lebih\",\"favorite\",\"bitches\",\"forever\",\"\\u0644\\u064a\",\"final\",\"read\",\"alguien\",\"open\",\"yourself\",\"ese\",\"che\",\"sex\",\"yaa\",\"car\",\"direction\",\"tidak\",\"seu\",\"gets\",\"left\",\"re\",\"jam\",\"enough\",\"\\u0625\\u0644\\u0627\",\"once\",\"\\u2019\",\"part\",\"cada\",\"\\u5b9a\\u671f\",\"\\u0644\\u0643\",\"een\",\"seen\",\"kak\",\"as\\u00ed\",\"nem\",\"\\u0639\\u0645\\u0644\",\"white\",\"told\",\"says\",\"esto\",\"sad\",\"mo\",\"fue\",\"yah\",\"summer\",\"\\u0647\",\"\\u2b55\",\"\\u00bb\",\"thats\",\"\\u0645\\u0639\",\"posted\",\"wants\",\"agora\",\"together\",\"fan\",\"men\",\"hear\",\"full\",\"\\u2600\",\"sigo\",\"pq\",\"dulu\",\"plus\",\"foi\",\"tudo\",\"\\u0647\\u0648\",\"ill\",\"\\u3042\",\"thinking\",\"wtf\",\"pagi\",\"mama\",\"kalau\",\"hati\",\"sexy\",\"sayang\",\"baik\",\"semua\",\"hola\",\"went\",\"vos\",\"tanto\",\"finally\",\"fb\",\"sea\",\"stupid\",\"tus\",\"seriously\",\"hora\",\"min\",\"pic\",\"estas\",\"turn\",\"hours\",\"excited\",\"nah\",\"buy\",\"saying\",\"mah\",\"break\",\"needs\",\"ce\",\"room\",\"choice\",\"far\",\"dead\",\"quero\",\"saw\",\"kids\",\"lil\",\"whole\",\"puede\",\"fall\",\"sus\",\"lost\",\"asi\",\"word\",\"\\u2639\",\"also\",\"\\u0631\\u064a\\u062a\\u0648\\u064a\\u062a\",\"probably\",\"everybody\",\"tarde\",\"run\",\"sei\",\"follback\",\"forget\",\"sweet\",\"welcome\",\"selamat\",\"\\uff3f\",\"sur\",\"place\",\"gusta\",\"sabe\",\"androidgames\",\"tp\",\"tiempo\",\"\\u0628\\u0633\",\"sou\",\"tuh\",\"vs\",\"eyes\",\"\\u0627\\u0646\\u0627\",\"picture\",\"das\",\"meet\",\"anak\",\"persona\",\"essa\",\"bored\",\"following\",\"nadie\",\"nobody\",\"dice\",\"alone\",\"sick\",\"red\",\"city\",\"cinta\",\"\\u6708\",\"linda\",\"dream\",\"story\",\"km\",\"het\",\"waiting\",\"^_^\",\"mine\",\"\\u0447\\u0442\\u043e\",\"reason\",\"kk\",\"\\u0644\\u0648\",\"online\",\"fast\",\"udh\",\"wanted\",\"op\",\"others\",\"gay\",\"n\\u2019t\",\"used\",\"sem\",\"understand\",\"moi\",\"sm\",\"aint\",\"donde\",\"bem\",\"which\",\"ng\",\"followback\",\"punya\",\"late\",\"anda\",\"tidur\",\"puedo\",\"early\",\"nd\",\"personas\",\"banyak\",\"\\u2705\",\"\\u278a\",\"trust\",\"noche\",\"tl\",\"\\uff1e\",\"\\u00ab\",\"af\",\"move\",\"pro\",\"bring\",\"ku\",\"called\",\"relationship\",\"idk\",\"hurt\",\"st\",\"pernah\",\"pessoas\",\"hello\",\"uno\",\"unfollowers\",\"cry\"],\"x\":{\"__ndarray__\":\"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\",\"dtype\":\"float32\",\"shape\":[1000]},\"y\":{\"__ndarray__\":\"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\",\"dtype\":\"float32\",\"shape\":[1000]}},\"selected\":{\"id\":\"1051\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"1050\",\"type\":\"UnionRenderers\"}},\"id\":\"1001\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1051\",\"type\":\"Selection\"},{\"attributes\":{},\"id\":\"1022\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"data_source\":{\"id\":\"1001\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"1037\",\"type\":\"Scatter\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1038\",\"type\":\"Scatter\"},\"selection_glyph\":null,\"view\":{\"id\":\"1040\",\"type\":\"CDSView\"}},\"id\":\"1039\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1050\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"1009\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1025\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"1007\",\"type\":\"LinearScale\"},{\"attributes\":{\"callback\":null,\"tooltips\":[[\"token\",\"@token\"]]},\"id\":\"1041\",\"type\":\"HoverTool\"},{\"attributes\":{\"callback\":null},\"id\":\"1003\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1026\",\"type\":\"HelpTool\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.25},\"fill_color\":{\"field\":\"color\"},\"line_alpha\":{\"value\":0.25},\"line_color\":{\"field\":\"color\"},\"size\":{\"units\":\"screen\",\"value\":10},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1037\",\"type\":\"Scatter\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":{\"id\":\"1022\",\"type\":\"WheelZoomTool\"},\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1021\",\"type\":\"PanTool\"},{\"id\":\"1022\",\"type\":\"WheelZoomTool\"},{\"id\":\"1023\",\"type\":\"BoxZoomTool\"},{\"id\":\"1024\",\"type\":\"SaveTool\"},{\"id\":\"1025\",\"type\":\"ResetTool\"},{\"id\":\"1026\",\"type\":\"HelpTool\"},{\"id\":\"1041\",\"type\":\"HoverTool\"}]},\"id\":\"1027\",\"type\":\"Toolbar\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"plot\":null,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"1029\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"size\":{\"units\":\"screen\",\"value\":10},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1038\",\"type\":\"Scatter\"},{\"attributes\":{},\"id\":\"1048\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1012\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1046\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"callback\":null},\"id\":\"1005\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1017\",\"type\":\"BasicTicker\"},{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"1002\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"1017\",\"type\":\"BasicTicker\"}},\"id\":\"1020\",\"type\":\"Grid\"},{\"attributes\":{\"plot\":null,\"text\":\"\"},\"id\":\"1044\",\"type\":\"Title\"}],\"root_ids\":[\"1002\"]},\"title\":\"Bokeh Application\",\"version\":\"1.0.4\"}};\n",
              "  var render_items = [{\"docid\":\"df5b4d75-669a-431a-b23b-4a87510aa0c8\",\"roots\":{\"1002\":\"91b43ce5-c674-40fb-abe3-253302069d3d\"}}];\n",
              "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
              "\n",
              "  }\n",
              "  if (root.Bokeh !== undefined) {\n",
              "    embed_document(root);\n",
              "  } else {\n",
              "    var attempts = 0;\n",
              "    var timer = setInterval(function(root) {\n",
              "      if (root.Bokeh !== undefined) {\n",
              "        embed_document(root);\n",
              "        clearInterval(timer);\n",
              "      }\n",
              "      attempts++;\n",
              "      if (attempts > 100) {\n",
              "        console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
              "        clearInterval(timer);\n",
              "      }\n",
              "    }, 10, root)\n",
              "  }\n",
              "})(window);"
            ],
            "application/vnd.bokehjs_exec.v0+json": ""
          },
          "metadata": {
            "tags": [],
            "application/vnd.bokehjs_exec.v0+json": {
              "id": "1002"
            }
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div style=\"display: table;\"><div style=\"display: table-row;\"><div style=\"display: table-cell;\"><b title=\"bokeh.plotting.figure.Figure\">Figure</b>(</div><div style=\"display: table-cell;\">id&nbsp;=&nbsp;'1002', <span id=\"1107\" style=\"cursor: pointer;\">&hellip;)</span></div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">above&nbsp;=&nbsp;[],</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">aspect_scale&nbsp;=&nbsp;1,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">background_fill_alpha&nbsp;=&nbsp;{'value': 1.0},</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">background_fill_color&nbsp;=&nbsp;{'value': '#ffffff'},</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">below&nbsp;=&nbsp;[LinearAxis(id='1011', ...)],</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">border_fill_alpha&nbsp;=&nbsp;{'value': 1.0},</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">border_fill_color&nbsp;=&nbsp;{'value': '#ffffff'},</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">css_classes&nbsp;=&nbsp;[],</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">disabled&nbsp;=&nbsp;False,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">extra_x_ranges&nbsp;=&nbsp;{},</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">extra_y_ranges&nbsp;=&nbsp;{},</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">h_symmetry&nbsp;=&nbsp;True,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">height&nbsp;=&nbsp;None,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">hidpi&nbsp;=&nbsp;True,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">js_event_callbacks&nbsp;=&nbsp;{},</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">js_property_callbacks&nbsp;=&nbsp;{},</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">left&nbsp;=&nbsp;[LinearAxis(id='1016', ...)],</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">lod_factor&nbsp;=&nbsp;10,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">lod_interval&nbsp;=&nbsp;300,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">lod_threshold&nbsp;=&nbsp;2000,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">lod_timeout&nbsp;=&nbsp;500,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">match_aspect&nbsp;=&nbsp;False,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">min_border&nbsp;=&nbsp;5,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">min_border_bottom&nbsp;=&nbsp;None,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">min_border_left&nbsp;=&nbsp;None,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">min_border_right&nbsp;=&nbsp;None,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">min_border_top&nbsp;=&nbsp;None,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">name&nbsp;=&nbsp;None,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_alpha&nbsp;=&nbsp;{'value': 1.0},</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_cap&nbsp;=&nbsp;'butt',</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_color&nbsp;=&nbsp;{'value': '#e5e5e5'},</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_dash&nbsp;=&nbsp;[],</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_dash_offset&nbsp;=&nbsp;0,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_join&nbsp;=&nbsp;'bevel',</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_width&nbsp;=&nbsp;{'value': 1},</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">output_backend&nbsp;=&nbsp;'canvas',</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">plot_height&nbsp;=&nbsp;400,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">plot_width&nbsp;=&nbsp;600,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">renderers&nbsp;=&nbsp;[LinearAxis(id='1011', ...), Grid(id='1015', ...), LinearAxis(id='1016', ...), Grid(id='1020', ...), BoxAnnotation(id='1029', ...), GlyphRenderer(id='1039', ...)],</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">right&nbsp;=&nbsp;[],</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">sizing_mode&nbsp;=&nbsp;'fixed',</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">subscribed_events&nbsp;=&nbsp;[],</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">tags&nbsp;=&nbsp;[],</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">title&nbsp;=&nbsp;Title(id='1044', ...),</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">title_location&nbsp;=&nbsp;'above',</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">toolbar&nbsp;=&nbsp;Toolbar(id='1027', ...),</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">toolbar_location&nbsp;=&nbsp;'right',</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">toolbar_sticky&nbsp;=&nbsp;True,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">v_symmetry&nbsp;=&nbsp;False,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">width&nbsp;=&nbsp;None,</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">x_range&nbsp;=&nbsp;DataRange1d(id='1003', ...),</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">x_scale&nbsp;=&nbsp;LinearScale(id='1007', ...),</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">y_range&nbsp;=&nbsp;DataRange1d(id='1005', ...),</div></div><div class=\"1106\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">y_scale&nbsp;=&nbsp;LinearScale(id='1009', ...))</div></div></div>\n",
              "<script>\n",
              "(function() {\n",
              "  var expanded = false;\n",
              "  var ellipsis = document.getElementById(\"1107\");\n",
              "  ellipsis.addEventListener(\"click\", function() {\n",
              "    var rows = document.getElementsByClassName(\"1106\");\n",
              "    for (var i = 0; i < rows.length; i++) {\n",
              "      var el = rows[i];\n",
              "      el.style.display = expanded ? \"none\" : \"table-row\";\n",
              "    }\n",
              "    ellipsis.innerHTML = expanded ? \"&hellip;)\" : \"&lsaquo;&lsaquo;&lsaquo;\";\n",
              "    expanded = !expanded;\n",
              "  });\n",
              "})();\n",
              "</script>\n"
            ],
            "text/plain": [
              "Figure(id='1002', ...)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4J1pYRVq6a1",
        "colab_type": "text"
      },
      "source": [
        "### Visualizing neighbors with t-SNE\n",
        "PCA is nice but it's strictly linear and thus only able to capture coarse high-level structure of the data.\n",
        "\n",
        "If we instead want to focus on keeping neighboring points near, we could use TSNE, which is itself an embedding method. Here you can read __[more on TSNE](https://distill.pub/2016/misread-tsne/)__."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaJXQ-fJq6a6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "outputId": "b473d656-b594-4985-9387-caff3eff6bcd"
      },
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# map word vectors onto 2d plane with TSNE. hint: use verbose=100 to see what it's doing.\n",
        "# normalize them as just lke with pca\n",
        "\n",
        "tsne = TSNE(n_components=2, verbose=100)\n",
        "word_tsne = tsne.fit_transform(word_vectors)\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[t-SNE] Computing 91 nearest neighbors...\n",
            "[t-SNE] Indexed 1000 samples in 0.014s...\n",
            "[t-SNE] Computed neighbors for 1000 samples in 0.231s...\n",
            "[t-SNE] Computed conditional probabilities for sample 1000 / 1000\n",
            "[t-SNE] Mean sigma: 1.716134\n",
            "[t-SNE] Computed conditional probabilities in 0.058s\n",
            "[t-SNE] Iteration 50: error = 69.2394791, gradient norm = 0.3069762 (50 iterations in 15.012s)\n",
            "[t-SNE] Iteration 100: error = 68.0914688, gradient norm = 0.3078671 (50 iterations in 10.830s)\n",
            "[t-SNE] Iteration 150: error = 69.6902008, gradient norm = 0.2760301 (50 iterations in 15.792s)\n",
            "[t-SNE] Iteration 200: error = 67.6233597, gradient norm = 0.3166763 (50 iterations in 225.556s)\n",
            "[t-SNE] Iteration 250: error = 69.1096039, gradient norm = 0.2998538 (50 iterations in 377.626s)\n",
            "[t-SNE] KL divergence after 250 iterations with early exaggeration: 69.109604\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-75d79811db6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtsne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mword_tsne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/manifold/t_sne.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mEmbedding\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlow\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdimensional\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m         \"\"\"\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/manifold/t_sne.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, skip_num_points)\u001b[0m\n\u001b[1;32m    811\u001b[0m                           \u001b[0mX_embedded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_embedded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m                           \u001b[0mneighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneighbors_nn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 813\u001b[0;31m                           skip_num_points=skip_num_points)\n\u001b[0m\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m     def _tsne(self, P, degrees_of_freedom, n_samples, X_embedded,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/manifold/t_sne.py\u001b[0m in \u001b[0;36m_tsne\u001b[0;34m(self, P, degrees_of_freedom, n_samples, X_embedded, neighbors, skip_num_points)\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mopt_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_iter_without_progress'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_without_progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m             params, kl_divergence, it = _gradient_descent(obj_func, params,\n\u001b[0;32m--> 864\u001b[0;31m                                                           **opt_args)\n\u001b[0m\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0;31m# Save the final number of iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/manifold/t_sne.py\u001b[0m in \u001b[0;36m_gradient_descent\u001b[0;34m(objective, p0, it, n_iter, n_iter_check, n_iter_without_progress, momentum, learning_rate, min_gain, min_grad_norm, verbose, args, kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'compute_error'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_convergence\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mgrad_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/manifold/t_sne.py\u001b[0m in \u001b[0;36m_kl_divergence_bh\u001b[0;34m(params, P, degrees_of_freedom, n_samples, n_components, angle, skip_num_points, verbose, compute_error)\u001b[0m\n\u001b[1;32m    256\u001b[0m                                       \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                                       \u001b[0mdof\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdegrees_of_freedom\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m                                       compute_error=compute_error)\n\u001b[0m\u001b[1;32m    259\u001b[0m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdegrees_of_freedom\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdegrees_of_freedom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJRmYmykcHTE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_tsne = StandardScaler().fit_transform(word_tsne)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "P8WVhWRtq6bN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "draw_vectors(word_tsne[:, 0], word_tsne[:, 1], color='green', token=words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQn36JIWq6bV",
        "colab_type": "text"
      },
      "source": [
        "### Visualizing phrases\n",
        "\n",
        "Word embeddings can also be used to represent short phrases. The simplest way is to take __an average__ of vectors for all tokens in the phrase with some weights.\n",
        "\n",
        "This trick is useful to identify what data are you working with: find if there are any outliers, clusters or other artefacts.\n",
        "\n",
        "Let's try this new hammer on our data!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jhXzOM_dA8M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "9fc5fe52-a588-43d5-cc96-fbd232152ae4"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yO-Qi85oq6bX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "6b61b304-9669-4e58-dd41-dec4e8f61b26"
      },
      "source": [
        "def get_phrase_embedding(phrase):\n",
        "    \"\"\"\n",
        "    Convert phrase to a vector by aggregating it's word embeddings. See description above.\n",
        "    \"\"\"\n",
        "    # 1. lowercase phrase\n",
        "    phrase_lower = phrase.lower()\n",
        "    # 2. tokenize phrase\n",
        "    tokens = nltk.word_tokenize(phrase)\n",
        "    # 3. average word vectors for all words in tokenized phrase\n",
        "    # skip words that are not in model's vocabulary\n",
        "    # if all words are missing from vocabulary, return zeros\n",
        "    token_vectors = []\n",
        "    for token in tokens:\n",
        "      try: \n",
        "        token_vectors.append(model.get_vector(token))\n",
        "      except:\n",
        "        token_vectors.append(0)\n",
        "    avg_vector = []\n",
        "    for vec in token_vectors:\n",
        "      try:\n",
        "        sum = 0\n",
        "        for n in vec:\n",
        "          sum += n\n",
        "        avg_vector.append(sum/len(vec))\n",
        "      except:\n",
        "        avg_vector.append(0)\n",
        "    vector = np.zeros([model.vector_size], dtype='float32')\n",
        "    print(vector)\n",
        "    #print(avg_vector)\n",
        "    return avg_vector\n",
        "\n",
        "\n",
        "    \n",
        "  #avg_\n",
        "    \n",
        "    # YOUR CODE\n",
        "    \n",
        "    #return vector\n",
        "        \n",
        "get_phrase_embedding('What a day!')\n",
        "    "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0.14628329104743898, -0.18111635744571686, 0.011714237494743429]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3jvGnr1q6be",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "089bc877-fc0e-40ed-f65e-6b85de983222"
      },
      "source": [
        "vector = get_phrase_embedding(\"I'm very sure. This never happened to me before...\")\n",
        "\n",
        "assert np.allclose(vector[::10],\n",
        "                   np.array([ 0.31807372, -0.02558171,  0.0933293 , -0.1002182 , -1.0278689 ,\n",
        "                             -0.16621883,  0.05083408,  0.17989802,  1.3701859 ,  0.08655966],\n",
        "                              dtype=np.float32))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-00c1fbf57af0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                    np.array([ 0.31807372, -0.02558171,  0.0933293 , -0.1002182 , -1.0278689 ,\n\u001b[1;32m      5\u001b[0m                              -0.16621883,  0.05083408,  0.17989802,  1.3701859 ,  0.08655966],\n\u001b[0;32m----> 6\u001b[0;31m                               dtype=np.float32))\n\u001b[0m",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mallclose\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mallclose\u001b[0;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[1;32m   2169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2170\u001b[0m     \"\"\"\n\u001b[0;32m-> 2171\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0matol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mequal_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mequal_nan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2172\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36misclose\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36misclose\u001b[0;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[1;32m   2270\u001b[0m     \u001b[0myfin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2271\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxfin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myfin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2272\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwithin_tol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2274\u001b[0m         \u001b[0mfinite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxfin\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0myfin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mwithin_tol\u001b[0;34m(x, y, atol, rtol)\u001b[0m\n\u001b[1;32m   2256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwithin_tol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2257\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2258\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mless_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrtol\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2260\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,) (10,) "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pe8IJDVdq6bq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# let's only consider ~5k phrases for a first run.\n",
        "chosen_phrases = data[::len(data) // 1000]\n",
        "\n",
        "# compute vectors for chosen phrases\n",
        "phrase_vectors = # YOUR CODE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HqEYYg-q6bx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert isinstance(phrase_vectors, np.ndarray) and np.isfinite(phrase_vectors).all()\n",
        "assert phrase_vectors.shape == (len(chosen_phrases), model.vector_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Th8Fravq6b5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# map vectors into 2d space with pca, tsne or your other method of choice\n",
        "# don't forget to normalize\n",
        "\n",
        "phrase_vectors_2d = TSNE(verbose=1000).fit_transform(phrase_vectors)\n",
        "\n",
        "phrase_vectors_2d = (phrase_vectors_2d - phrase_vectors_2d.mean(axis=0)) / phrase_vectors_2d.std(axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ae9CyGSq6cB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "draw_vectors(phrase_vectors_2d[:, 0], phrase_vectors_2d[:, 1],\n",
        "             phrase=[phrase[:50] for phrase in chosen_phrases],\n",
        "             radius=20,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l41sNnfDq6cL",
        "colab_type": "text"
      },
      "source": [
        "Finally, let's build a simple \"similar question\" engine with phrase embeddings we've built."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqzFXTRCq6cN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compute vector embedding for all lines in data\n",
        "data_vectors = np.array([get_phrase_embedding(l) for l in data])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeh96OrHq6cW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_nearest(query, k=10):\n",
        "    \"\"\"\n",
        "    given text line (query), return k most similar lines from data, sorted from most to least similar\n",
        "    similarity should be measured as cosine between query and line embedding vectors\n",
        "    hint: it's okay to use global variables: data and data_vectors. see also: np.argpartition, np.argsort\n",
        "    \"\"\"\n",
        "    # YOUR CODE\n",
        "    \n",
        "    return <YOUR CODE: top-k lines starting from most similar>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wks8Pfbjq6ct",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = find_nearest(query=\"How do i enter the matrix?\", k=10)\n",
        "\n",
        "print(''.join(results))\n",
        "\n",
        "assert len(results) == 10 and isinstance(results[0], str)\n",
        "assert results[0] == 'How do I get to the dark web?\\n'\n",
        "assert results[3] == 'What can I do to save the world?\\n'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Co7f-S08q6c5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "find_nearest(query=\"How does Trump?\", k=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQwoPc3Xq6dA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "find_nearest(query=\"Why don't i ask a question myself?\", k=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "FAeVeVp5q6dO",
        "colab_type": "text"
      },
      "source": [
        "__Now what?__\n",
        "* Try running TSNE on all data, not just 1000 phrases\n",
        "* See what other embeddings are there in the model zoo: `gensim.downloader.info()`\n",
        "* Take a look at [FastText](https://github.com/facebookresearch/fastText) embeddings\n",
        "* Optimize find_nearest with locality-sensitive hashing: use [nearpy](https://github.com/pixelogik/NearPy) or `sklearn.neighbors`."
      ]
    }
  ]
}